{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64f5cce9-6269-4572-aee3-93d578cd32b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradientinis: pradinis x(0)\n",
      "---------------------------\n",
      "           1            2\n",
      "\n",
      "Gradientinis: f(x(0))=12, ||∇Ψ||2=7.81025134106, step=0.1\n",
      "\n",
      "\n",
      "[Gradientinis] it=1: ∇Ψ(x)\n",
      "--------------------------\n",
      "           6           -5\n",
      "\n",
      "[Gradientinis] it=1: f_old=12 → f_new=6.81 (step=0.1)\n",
      "\n",
      "Gradientinis: sprendinys x\n",
      "--------------------------\n",
      "         0.4          2.5\n",
      "\n",
      "Gradientinis: f(x)=6.80999964383, ||∇Ψ(x)||2=5.59156525204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable, List, Tuple, Optional\n",
    "import math\n",
    "\n",
    "Vec = List[float]\n",
    "Mat = List[List[float]]\n",
    "\n",
    "# ============================\n",
    "# Spausdinimas ir bazinė algebra\n",
    "# ============================\n",
    "def print_matrix(M: Mat, title: str = \"\", fmt: str = \"{:12.6g}\"):\n",
    "    if title:\n",
    "        print(f\"\\n{title}\\n\" + \"-\" * len(title))\n",
    "    for r in M:\n",
    "        print(\" \".join(fmt.format(v) for v in r))\n",
    "    print()\n",
    "\n",
    "def print_vector(v: Vec, title: str = \"\", fmt: str = \"{:12.6g}\"):\n",
    "    if title:\n",
    "        print(f\"\\n{title}\\n\" + \"-\" * len(title))\n",
    "    print(\" \".join(fmt.format(x) for x in v))\n",
    "    print()\n",
    "\n",
    "def norm2(v: Vec) -> float:\n",
    "    return math.sqrt(sum(x*x for x in v))\n",
    "\n",
    "def vec_add(a: Vec, b: Vec) -> Vec:\n",
    "    return [a[i] + b[i] for i in range(len(a))]\n",
    "\n",
    "def vec_sub(a: Vec, b: Vec) -> Vec:\n",
    "    return [a[i] - b[i] for i in range(len(a))]\n",
    "\n",
    "def vec_scale(a: Vec, s: float) -> Vec:\n",
    "    return [s*ai for ai in a]\n",
    "\n",
    "def dot(a: Vec, b: Vec) -> float:\n",
    "    return sum(a[i]*b[i] for i in range(len(a)))\n",
    "\n",
    "def matvec(A: Mat, x: Vec) -> Vec:\n",
    "    return [sum(A[i][j]*x[j] for j in range(len(x))) for i in range(len(A))]\n",
    "\n",
    "def eye(n: int) -> Mat:\n",
    "    return [[1.0 if i==j else 0.0 for j in range(n)] for i in range(n)]\n",
    "\n",
    "def deepcopy(A: Mat) -> Mat:\n",
    "    return [row[:] for row in A]\n",
    "\n",
    "# ============================\n",
    "# 0) SKAITINIS FUNKCIJOS GRADIENTAS\n",
    "#    ∇Ψ(x) ≈ [(Ψ(x+he1)-Ψ(x))/h, ...]\n",
    "# ============================\n",
    "def numerical_gradient(Psi: Callable[[Vec], float], x: Vec, h: float = 1e-6, verbose: bool=True) -> Vec:\n",
    "    fx = Psi(x)\n",
    "    g = [0.0]*len(x)\n",
    "    for j in range(len(x)):\n",
    "        xh = x[:]\n",
    "        xh[j] += h\n",
    "        g[j] = (Psi(xh) - fx) / h\n",
    "    if verbose:\n",
    "        print_vector(x, \"Gradiento skaičiavimas taške x\")\n",
    "        print_vector(g, \"∇Ψ(x) (skaitinis įvertis)\")\n",
    "        print(f\"||∇Ψ(x)||2 = {norm2(g):.12g}\\n\")\n",
    "    return g\n",
    "\n",
    "# ============================\n",
    "# Atgalinio žingsnio (Armijo) paieška\n",
    "# ============================\n",
    "def backtracking(Psi: Callable[[Vec], float],\n",
    "                 x: Vec, d: Vec, g: Vec,\n",
    "                 alpha0: float = 1.0,\n",
    "                 c: float = 1e-4, rho: float = 0.5,\n",
    "                 verbose: bool=True) -> float:\n",
    "    \"\"\"\n",
    "    Randa žingsnį α > 0 tenkinant Armijo sąlygą:\n",
    "      Ψ(x + α d) ≤ Ψ(x) + c α g^T d\n",
    "    \"\"\"\n",
    "    fx = Psi(x)\n",
    "    gd = dot(g, d)\n",
    "    alpha = alpha0\n",
    "    k = 0\n",
    "    while True:\n",
    "        x_new = vec_add(x, vec_scale(d, alpha))\n",
    "        f_new = Psi(x_new)\n",
    "        if f_new <= fx + c*alpha*gd:\n",
    "            if verbose:\n",
    "                print(f\"[Backtracking] α={alpha:.6g}, f_old={fx:.6g}, f_new={f_new:.6g}  ✓\")\n",
    "            return alpha\n",
    "        if alpha < 1e-16:\n",
    "            if verbose:\n",
    "                print(f\"[Backtracking] α nukrito iki {alpha:.1e} – grąžinu minimalų.\")\n",
    "            return alpha\n",
    "        if verbose and k < 3:\n",
    "            print(f\"[Backtracking] α={alpha:.6g} netinka (f_new={f_new:.6g}) → mažinu\")\n",
    "        alpha *= rho\n",
    "        k += 1\n",
    "\n",
    "# ============================\n",
    "# 1) MINIMIZAVIMAS PAGAL GRADIENTĄ (fiksuoto dydžio žingsnis kryptimi -ĝ)\n",
    "#    x_{k+1} = x_k - s * ĝ(x_k), kur ĝ = ∇Ψ / ||∇Ψ||\n",
    "# ============================\n",
    "def gradient_method(Psi: Callable[[Vec], float],\n",
    "                    x0: Vec,\n",
    "                    step: float = 1e-1,\n",
    "                    eps: float = 1e-8,\n",
    "                    nitmax: int = 10_000,\n",
    "                    verbose: bool=True) -> Vec:\n",
    "    x = x0[:]\n",
    "    f = Psi(x)\n",
    "    g = numerical_gradient(Psi, x, verbose=False)\n",
    "    print_vector(x, \"Gradientinis: pradinis x(0)\")\n",
    "    print(f\"Gradientinis: f(x(0))={f:.12g}, ||∇Ψ||2={norm2(g):.12g}, step={step}\\n\")\n",
    "\n",
    "    for it in range(1, nitmax+1):\n",
    "        g = numerical_gradient(Psi, x, verbose=False)  # skaitinis ∇F\n",
    "        gnorm = norm2(g)\n",
    "        if gnorm < eps:\n",
    "            print(f\"[Gradientinis] Sustojau: ||∇Ψ||2 < eps ({gnorm:.3e} < {eps}).\")\n",
    "            break\n",
    "    \n",
    "        d = vec_scale(g, -1.0)           # -∇F (ne normalizuotas)\n",
    "        x_new = vec_add(x, vec_scale(d, step))\n",
    "        f_old = f\n",
    "        f_new = Psi(x_new)\n",
    "        if verbose:\n",
    "            print_vector(g, f\"[Gradientinis] it={it}: ∇Ψ(x)\")\n",
    "            print(f\"[Gradientinis] it={it}: f_old={f_old:.6g} → f_new={f_new:.6g} (step={step:.3g})\")\n",
    "    \n",
    "        x, f = x_new, f_new\n",
    "    \n",
    "        if gnorm < eps or step < 1e-16:\n",
    "            print(f\"[Gradientinis] Sustojau: ||∇Ψ||2={gnorm:.3e}, step={step:.1e}\")\n",
    "            break\n",
    "\n",
    "\n",
    "    print_vector(x, \"Gradientinis: sprendinys x\")\n",
    "    print(f\"Gradientinis: f(x)={Psi(x):.12g}, ||∇Ψ(x)||2={norm2(numerical_gradient(Psi, x, verbose=False)):.12g}\\n\")\n",
    "    return x\n",
    "\n",
    "# ============================\n",
    "# 2) GREIČIAUSIO NUSILEIDIMO METODAS (su Armijo atgaliniu žingsniu)\n",
    "#    x_{k+1} = x_k + α_k d_k, d_k = -∇Ψ(x_k)\n",
    "# ============================\n",
    "def steepest_descent(Psi: Callable[[Vec], float],\n",
    "                     x0: Vec,\n",
    "                     alpha0: float = 1.0,\n",
    "                     eps: float = 1e-8,\n",
    "                     nitmax: int = 10_000,\n",
    "                     verbose: bool=True) -> Vec:\n",
    "    x = x0[:]\n",
    "    f = Psi(x)\n",
    "    print_vector(x, \"Greičiausio nusileidimo: pradinis x(0)\")\n",
    "    print(f\"Greičiausio nusileidimo: f(x(0))={f:.12g}\\n\")\n",
    "\n",
    "    for it in range(1, nitmax+1):\n",
    "        g = numerical_gradient(Psi, x, verbose=False)\n",
    "        gnorm = norm2(g)\n",
    "        if gnorm < eps:\n",
    "            print(f\"[Steepest] Sustojau: ||∇Ψ||2 < eps ({gnorm:.3e} < {eps}).\")\n",
    "            break\n",
    "\n",
    "        d = vec_scale(g, -1.0)                          # kryptis = -∇Ψ\n",
    "        alpha = backtracking(Psi, x, d, g, alpha0=alpha0, verbose=verbose)\n",
    "        x_new = vec_add(x, vec_scale(d, alpha))\n",
    "        f_new = Psi(x_new)\n",
    "\n",
    "        if verbose:\n",
    "            print_vector(g,     f\"[Steepest] it={it}: ∇Ψ(x)\")\n",
    "            print(f\"[Steepest] it={it}: f_old={f:.6g} → f_new={f_new:.6g}, α={alpha:.6g}\")\n",
    "\n",
    "        x, f = x_new, f_new\n",
    "        if alpha < 1e-16:\n",
    "            print(\"[Steepest] Sustojau: α ~ 0.\")\n",
    "            break\n",
    "        if gnorm < eps:\n",
    "            break\n",
    "\n",
    "    print_vector(x, \"Greičiausio nusileidimo: sprendinys x\")\n",
    "    print(f\"Greičiausio nusileidimo: f(x)={Psi(x):.12g}, ||∇Ψ(x)||2={norm2(numerical_gradient(Psi, x, verbose=False)):.12g}\\n\")\n",
    "    return x\n",
    "\n",
    "# ============================\n",
    "# 3) KVAZI-GRADIENTO METODAS NLS atveju:\n",
    "#    Ψ(x) = 1/2 ||f(x)||^2,  g(x) = J(x)^T f(x)\n",
    "#    Approx. J ≈ A, atnaujinam Broideno (good) rang-1 formule:\n",
    "#    A_{k+1} = A_k + ((y - A_k s) s^T) / (s^T s),  y = f(x_{k+1}) - f(x_k)\n",
    "#    Kryptis d = - g = - A^T f, žingsnis – Armijo.\n",
    "# ============================\n",
    "def quasi_gradient_nls(f: Callable[[Vec], Vec],\n",
    "                       x0: Vec,\n",
    "                       A0: Optional[Mat] = None,     # pradinė Jakobio aproksimacija; jei None – skaitinė J(x0)\n",
    "                       h_jac: float = 1e-6,\n",
    "                       alpha0: float = 1.0,\n",
    "                       eps: float = 1e-8,\n",
    "                       nitmax: int = 1_000,\n",
    "                       verbose: bool=True) -> Vec:\n",
    "    def Psi(x: Vec) -> float:\n",
    "        fx = f(x)\n",
    "        return 0.5*dot(fx, fx)\n",
    "\n",
    "    # pradžia\n",
    "    x = x0[:]\n",
    "    fx = f(x)\n",
    "    m, n = len(fx), len(x)\n",
    "\n",
    "    # jeigu A0 neduota – pasidarom skaitinį J(x0)\n",
    "    if A0 is None:\n",
    "        A = [[0.0]*n for _ in range(m)]\n",
    "        f0 = fx[:]\n",
    "        for j in range(n):\n",
    "            xh = x[:]; xh[j] += h_jac\n",
    "            df = [f(xh)[i] - f0[i] for i in range(m)]\n",
    "            for i in range(m):\n",
    "                A[i][j] = df[i]/h_jac\n",
    "        if verbose:\n",
    "            print_matrix(A, \"Kvazi-gradiento: pradinė A0 (skaitinė J(x0))\")\n",
    "    else:\n",
    "        A = deepcopy(A0)\n",
    "        if verbose:\n",
    "            print_matrix(A, \"Kvazi-gradiento: pradinė A0 (duota)\")\n",
    "\n",
    "    print_vector(x,  \"Kvazi-gradiento: x(0)\")\n",
    "    print_vector(fx, \"Kvazi-gradiento: f(x(0))\")\n",
    "    print(f\"Kvazi-gradiento: Ψ(x(0)) = {0.5*dot(fx,fx):.12g}\\n\")\n",
    "\n",
    "    for it in range(1, nitmax+1):\n",
    "        # g = A^T f\n",
    "        g = [sum(A[i][j]*fx[i] for i in range(m)) for j in range(n)]\n",
    "        gnorm = norm2(g)\n",
    "        if gnorm < eps:\n",
    "            print(f\"[QG] Sustojau: ||g||2 < eps ({gnorm:.3e} < {eps}).\")\n",
    "            break\n",
    "\n",
    "        d = vec_scale(g, -1.0)  # kryptis\n",
    "        # Armijo žingsnis\n",
    "        alpha = backtracking(Psi, x, d, g, alpha0=alpha0, verbose=verbose)\n",
    "        s = vec_scale(d, alpha)\n",
    "        x_new = vec_add(x, s)\n",
    "        fx_new = f(x_new)\n",
    "\n",
    "        if verbose:\n",
    "            print_vector(g,     f\"[QG] it={it}: g = A^T f\")\n",
    "            print(f\"[QG] it={it}: Ψ_old={0.5*dot(fx,fx):.6g} → Ψ_new={0.5*dot(fx_new,fx_new):.6g}, α={alpha:.6g}\")\n",
    "\n",
    "        # Broideno (good) atnaujinimas A\n",
    "        y = vec_sub(fx_new, fx)           # f(x_{k+1}) - f(x_k)\n",
    "        sTs = dot(s, s)\n",
    "        if sTs < 1e-30:\n",
    "            print(\"[QG] s^T s ≈ 0 – praleidžiu A atnaujinimą.\")\n",
    "        else:\n",
    "            As = matvec(A, s)\n",
    "            diff = [y[i] - As[i] for i in range(m)]\n",
    "            # A <- A + diff * s^T / (s^T s)\n",
    "            for i in range(m):\n",
    "                for j in range(n):\n",
    "                    A[i][j] += diff[i]*s[j]/sTs\n",
    "            if verbose:\n",
    "                print_matrix(A, f\"[QG] it={it}: atnaujinta A\")\n",
    "\n",
    "        x, fx = x_new, fx_new\n",
    "\n",
    "        if norm2(g) < eps or alpha < 1e-16:\n",
    "            print(f\"[QG] Sustojau: ||g||2={norm2(g):.3e}, α={alpha:.1e}\")\n",
    "            break\n",
    "\n",
    "    print_vector(x,  \"Kvazi-gradiento: sprendinys x\")\n",
    "    print_vector(fx, \"Kvazi-gradiento: f(x)\")\n",
    "    print(f\"Kvazi-gradiento: Ψ(x) = {0.5*dot(fx,fx):.12g},  ||g||2 ≈ {norm2([sum(A[i][j]*fx[i] for i in range(m)) for j in range(n)]):.12g}\\n\")\n",
    "    return x\n",
    "\n",
    "# ============================\n",
    "# MAIN — tik užkomentuoti paleidimai (atsikomentuok, ką nori matyti)\n",
    "# ============================\n",
    "def main():\n",
    "    # --- Pavyzdinė skaliarinė funkcija Ψ(x) (2D) ---\n",
    "    # \"Bowl + ridge\": minimumas ties (1, -2)\n",
    "    def Psi(x: Vec) -> float:\n",
    "        return x[0]**2 + (x[1] - 5)**2 + x[0]**2 * x[1]\n",
    "\n",
    "    x0 = [1.0, 2.0]\n",
    "\n",
    "    # --- 0) Skaitinis gradientas ---\n",
    "    # g = numerical_gradient(Psi, x0, h=1e-6, verbose=True)\n",
    "\n",
    "    # --- 1) Gradientinis metodas (fiksuotas žingsnio mastelis) ---\n",
    "    x_g = gradient_method(Psi, x0, step=0.1, eps=1e-8, nitmax=1, verbose=True)\n",
    "\n",
    "    # --- 2) Greičiausio nusileidimo metodas (Armijo) ---\n",
    "    # x_sd = steepest_descent(Psi, x0, alpha0=1.0, eps=1e-8, nitmax=2000, verbose=True)\n",
    "\n",
    "    # --- 3) Kvazi-gradiento metodas NLS atveju: Ψ(x)=1/2||f(x)||^2 ---\n",
    "    # Paimkim NLS pavyzdį iš ankstesnių pratybų:\n",
    "    # f1 = x1^2 + x2^2 - 2;  f2 = x1^2 - x2^2\n",
    "    def fNLS(x: Vec) -> Vec:\n",
    "        return [x[0]**2 + x[1]**2 - 2.0,\n",
    "                x[0]**2 - x[1]**2]\n",
    "    x0_nls = [-2.0, 0.5]\n",
    "    # x_qg = quasi_gradient_nls(fNLS, x0_nls, A0=None, alpha0=1.0, eps=1e-10, nitmax=200, verbose=True)\n",
    "\n",
    "    pass\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c22274-5ee1-4f32-a61f-3e5c28704a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
